#!/usr/bin/env python3
"""
CLI orchestrator for M1.5 digest processing, video rendering, publishing, and notifications.
"""

import click
import subprocess
import sys
import json
import os
from pathlib import Path
import logging
from datetime import datetime, timezone

# Compute base directory relative to script location
base_dir = Path(__file__).resolve().parent.parent

# Add parent directory to Python path for imports
sys.path.insert(0, str(base_dir))

from services.blog import BlogDigestBuilder
from services.publisher import publish_video
from services.notify import notify_story_discord, notify_digest_summary, get_webhook_url
from services.media import probe_duration, file_exists

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@click.command()
@click.option("--date", help="Date in YYYY-MM-DD format (defaults to today)")
@click.option("--render/--no-render", default=True, help="Render videos from story packets")
@click.option("--publish", type=click.Choice(["local", "r2"]), default="local", help="Publish target (local or r2)")
@click.option("--notify-discord/--no-notify-discord", default=True, help="Send Discord notifications")
@click.option("--write-blog/--no-write-blog", default=True, help="Generate blog markdown")
@click.option("--dry-run", is_flag=True, help="Dry run mode (no Discord notifications)")
@click.option("--verbose", "-v", is_flag=True, help="Verbose output")
def main(date, render, publish, notify_discord, write_blog, dry_run, verbose):
    """Process digest data for M1.5 pipeline."""
    
    if verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # Set default date to today if not provided
    if not date:
        date = datetime.now(timezone.utc).strftime("%Y-%m-%d")
    
    # Validate date format
    try:
        datetime.strptime(date, "%Y-%m-%d")
    except ValueError:
        click.echo("Error: Date must be in YYYY-MM-DD format", err=True)
        sys.exit(1)
    
    # Set publish target environment variable
    os.environ["PUBLISH_TARGET"] = publish
    
    click.echo(f"Processing digest for {date} with publish target: {publish}")
    
    # Step 1: Build/Load v2 digest
    click.echo("üîÑ Building v2 digest...")
    try:
        builder = BlogDigestBuilder()
        
        # Check if digest already exists and load it to preserve video paths
        existing_digest_path = base_dir / f"blogs/{date}/PRE-CLEANED-{date}_digest.json"
        existing_video_paths = {}  # Initialize to empty dict before checking
        if existing_digest_path.exists():
            with open(existing_digest_path, 'r') as f:
                existing_digest = json.load(f)
            
            # Preserve published video paths from existing digest
            for packet in existing_digest.get("story_packets", []):
                story_id = packet.get("id")
                video_path = packet.get("video", {}).get("path", "")
                if video_path and (video_path.startswith("/stories/") or video_path.startswith("http")):
                    existing_video_paths[story_id] = video_path
        
        # Build new digest
        digest = builder.build_digest(date)
        
        # Restore published video paths
        if existing_video_paths:
            for packet in digest.get("story_packets", []):
                story_id = packet.get("id")
                if story_id in existing_video_paths:
                    if "video" not in packet:
                        packet["video"] = {}
                    packet["video"]["path"] = existing_video_paths[story_id]
                    packet["video"]["status"] = "rendered"
        
        # Save digest to blogs directory
        digest_path = builder.save_digest(digest)
        click.echo(f"‚úì Digest built and saved to {digest_path}")
        
    except Exception as e:
        click.echo(f"‚úó Failed to build digest: {e}", err=True)
        sys.exit(1)
    
    # Step 2: Render and publish videos
    if render:
        click.echo("üîÑ Processing videos...")
        
        # Load updated digest
        with open(digest_path, 'r') as f:
            digest_data = json.load(f)
        
        story_packets = digest_data.get("story_packets", [])
        changed = False
        
        for packet in story_packets:
            story_id = packet.get("id")
            video_info = packet.get("video", {})
            explainer_info = packet.get("explainer", {})
            
            # Check if packet needs rendering based on video status and force_rerender flag
            explainer_status = explainer_info.get("status")
            video_status = video_info.get("status")
            force_rerender = video_info.get("force_rerender", False)
            
            # Only render if video is not rendered OR if force_rerender is set
            needs_rendering = video_status != "rendered" or force_rerender
            
            # Set force_rerender flag only when explainer status has changed since last render
            # This prevents perpetual re-renders when explainer status hasn't actually changed
            explainer_status_at_render = video_info.get("explainer_status_at_render")
            if explainer_status == "recorded" and video_status == "rendered" and explainer_status != explainer_status_at_render:
                video_info["force_rerender"] = True
                needs_rendering = True
            
            if needs_rendering:
                click.echo(f"  Rendering video for {story_id}...")
                
                # First, attempt to import the renderer module
                try:
                    from tools.renderer_html import render_for_packet
                except (ImportError, SyntaxError) as e:
                    click.echo(f"  ‚úó Failed to import renderer module for {story_id}: {e}", err=True)
                    click.echo(f"  ‚úó Cannot render video for packet {story_id} - skipping", err=True)
                    # Mark as failed due to import error
                    if "video" not in packet:
                        packet["video"] = {}
                    packet["video"]["status"] = "failed"
                    packet["video"]["error"] = f"Import error: {e}"
                    packet["video"]["force_rerender"] = False
                    changed = True
                    continue
                
                # Now attempt to render the video
                try:
                    # Render video using new HTML‚ÜíPNG renderer
                    out_dir = base_dir / f"out/videos/{date}"
                    out_mp4 = render_for_packet(packet, out_dir)
                    
                    # Update packet with video info
                    if "video" not in packet:
                        packet["video"] = {}
                    
                    # Normalize path to be relative to base_dir for publishing
                    try:
                        relative_path = Path(out_mp4).relative_to(base_dir)
                        video_path_for_publish = str(relative_path)
                    except ValueError:
                        # If out_mp4 is not relative to base_dir, use as-is
                        video_path_for_publish = out_mp4
                    
                    packet["video"]["status"] = "rendered"
                    packet["video"]["path"] = video_path_for_publish
                    packet["video"]["canvas"] = "1080x1920"
                    packet["video"]["force_rerender"] = False
                    # Store current explainer status to prevent unnecessary re-renders
                    packet["video"]["explainer_status_at_render"] = explainer_status
                    
                    # Get duration and calculate frames
                    from tools.renderer_html import get_renderer_config
                    
                    duration = probe_duration(out_mp4)
                    if duration:
                        packet["video"]["duration_s"] = round(duration, 2)
                        config = get_renderer_config()
                        
                        # Validate fps configuration before computing frames
                        fps = config.get("fps")
                        parsed_fps = None
                        
                        # Handle string values by attempting to parse
                        if isinstance(fps, str):
                            try:
                                parsed_fps = float(fps.strip())
                            except (ValueError, AttributeError):
                                pass
                        elif isinstance(fps, (int, float)):
                            parsed_fps = float(fps)
                        
                        if parsed_fps and parsed_fps > 0:
                            packet["video"]["frames"] = int(duration * parsed_fps)
                        else:
                            # Use sensible default if fps is missing or invalid
                            default_fps = 30
                            packet["video"]["frames"] = int(duration * default_fps)
                            click.echo(f"  ‚ö†Ô∏è Using default fps ({default_fps}) for {story_id} - config fps was invalid: {fps}")
                    
                    click.echo(f"  ‚úì Rendered video for {story_id}")
                    changed = True
                    
                except subprocess.CalledProcessError as e:
                    click.echo(f"  ‚úó Render failed for {story_id}: {e.stderr}", err=True)
                    # Mark as failed
                    if "video" not in packet:
                        packet["video"] = {}
                    packet["video"]["status"] = "failed"
                    packet["video"]["error"] = str(e)
                    packet["video"]["force_rerender"] = False
                    changed = True
                except Exception as e:
                    click.echo(f"  ‚úó Render failed for {story_id} (packet_id: {story_id}, out_dir: {out_dir}): {e}", err=True)
                    # Mark as failed
                    if "video" not in packet:
                        packet["video"] = {}
                    packet["video"]["status"] = "failed"
                    packet["video"]["error"] = str(e)
                    packet["video"]["force_rerender"] = False
                    changed = True
            else:
                click.echo(f"  ‚úì Video already rendered for {story_id}")
            
            # Publish video if rendered
            if packet.get("video", {}).get("status") == "rendered" and packet.get("video", {}).get("path"):
                local_path = packet["video"]["path"]
                # Only publish if it's a local path, not already published
                if local_path.startswith("out/videos/") and file_exists(local_path):
                    click.echo(f"  Publishing video for {story_id}...")
                    try:
                        public_path = publish_video(local_path, date, story_id)
                        packet["video"]["path"] = public_path
                        changed = True
                        click.echo(f"  ‚úì Published video for {story_id}: {public_path}")
                    except Exception as e:
                        click.echo(f"  ‚úó Publish failed for {story_id}: {e}", err=True)
                        # Don't fail the whole pipeline for publish errors
                elif local_path.startswith("/stories/") or local_path.startswith("http"):
                    click.echo(f"  ‚úì Video already published for {story_id}: {local_path}")
                else:
                    click.echo(f"  ‚ö†Ô∏è Local video not found for {story_id}: {local_path}")
            
            # Probe duration if missing
            if packet.get("video", {}).get("status") == "rendered" and not packet.get("video", {}).get("duration_s"):
                video_path = packet["video"].get("path", "")
                is_local_path = video_path and not video_path.startswith(("http://", "https://", "/stories/"))
                if video_path and (not is_local_path or file_exists(video_path)):
                    duration = probe_duration(video_path)
                    if duration:
                        packet["video"]["duration_s"] = round(duration, 2)
                        changed = True
                        click.echo(f"  ‚úì Probed duration for {story_id}: {duration}s")
        
        # Save updated digest if changed
        if changed:
            try:
                with open(digest_path, 'w') as f:
                    json.dump(digest_data, f, indent=2, default=str)
                click.echo("‚úì Updated digest with video information")
            except Exception as e:
                click.echo(f"‚úó Failed to save updated digest: {e}", err=True)
        else:
            click.echo("‚úì No video changes needed")
    
    # Step 3: Send Discord notifications
    if notify_discord:
        webhook_url = get_webhook_url()
        if not webhook_url:
            click.echo("‚ö†Ô∏è No Discord webhook URL configured, skipping notifications")
        else:
            click.echo("üîÑ Sending Discord notifications...")
            
            # Load digest data
            with open(digest_path, 'r') as f:
                digest_data = json.load(f)
            
            story_packets = digest_data.get("story_packets", [])
            success_count = 0
            
            for packet in story_packets:
                if not dry_run:
                    if notify_story_discord(packet, date, webhook_url):
                        success_count += 1
                else:
                    # Dry run - just print what would be sent
                    title = packet.get("title_human") or packet.get("title_raw", "Untitled")
                    click.echo(f"  Would notify: {title}")
                    success_count += 1
            
            # Send summary notification
            if story_packets:
                blog_url = f"{os.getenv('BLOG_BASE_URL', 'https://example.com')}/blog/{date}"
                if not dry_run:
                    notify_digest_summary(date, len(story_packets), blog_url, webhook_url)
                else:
                    click.echo(f"  Would send summary: {len(story_packets)} stories for {date}")
            
            click.echo(f"‚úì Discord: {success_count}/{len(story_packets)} notifications sent")
    
    # Step 4: Write blog markdown
    if write_blog:
        click.echo("üîÑ Generating blog markdown...")
        try:
            # Load digest data
            with open(digest_path, 'r') as f:
                data = json.load(f)
            
            # Generate markdown
            md_content = builder.generate_markdown(data)
            
            # Write to drafts directory
            out_path = base_dir / f"drafts/{date}.md"
            out_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(out_path, 'w') as f:
                f.write(md_content)
            
            click.echo(f"‚úì Blog: Markdown written to {out_path}")
            
        except Exception as e:
            click.echo(f"‚úó Blog generation failed: {e}", err=True)
            if not verbose:
                click.echo("Use --verbose for more details")
            sys.exit(1)
    
    # Initialize story_packets for summary if not already loaded
    if 'story_packets' not in locals():
        story_packets = []
        try:
            # Load digest to get accurate story count for summary
            with open(digest_path, 'r') as f:
                digest_data = json.load(f)
            story_packets = digest_data.get("story_packets", [])
        except Exception as e:
            click.echo(f"‚ö†Ô∏è Could not load digest for summary: {e}")
    
    click.echo(f"‚úÖ M1.5 pipeline completed for {date}")
    click.echo(f"üìä Summary:")
    click.echo(f"  - Digest: {digest_path}")
    click.echo(f"  - Blog: {base_dir / f'drafts/{date}.md'}")
    if story_packets:
        click.echo(f"  - Stories: {len(story_packets)}")
        rendered_count = sum(1 for p in story_packets if p.get("video", {}).get("status") == "rendered")
        click.echo(f"  - Videos rendered: {rendered_count}")


if __name__ == "__main__":
    main()
